extends: base.yaml

env:
  id: LunarLanderContinuous-v2
  normalize_obs: true
  normalize_reward: true

method: actor_critic
algorithm: td3
gamma: 0.99
tau: 0.005

actor:
  lr: 0.0003
critic:
  lr: 0.0003
  target_noise: 0.2
  noise_clip: 0.5
policy_delay: 2

replay:
  capacity: 1000000
  batch_size: 256
  start_learning: 10000

exploration:
  action_noise: gaussian
  stddev: 0.1

train_steps: 1000000

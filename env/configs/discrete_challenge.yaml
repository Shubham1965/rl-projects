extends: base.yaml

env:
  id: LunarLander-v2

method: value_based
algorithm: q_learning_replay_enhanced  # implements Double + Dueling + PER
gamma: 0.99

dueling: true
double: true

replay:
  capacity: 500000
  batch_size: 128
  start_learning: 10000
  prioritized: true
  per_alpha: 0.6
  per_beta_start: 0.4
  per_beta_end: 1.0
  per_anneal_steps: 300000

exploration:
  schedule: linear
  eps_start: 1.0
  eps_end: 0.05
  eps_decay_steps: 200000

target_network:
  type: hard
  update_every: 1000

grad_clip_norm: 10.0
train_steps: 800000
